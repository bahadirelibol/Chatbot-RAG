# Ã§alÄ±ÅŸtÄ±rmak iÃ§in : uvicorn main:app --reload 

# KÃ¼tÃ¼phanelerin Ä°Ã§eri AktarÄ±lmasÄ±
import time
from fastapi import FastAPI, Request, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from dotenv import load_dotenv
from typing import Optional, List, Dict 
import os
import json
import uuid
import datetime
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_chroma import Chroma

# Ã‡evre deÄŸiÅŸkenlerini yÃ¼kleme
load_dotenv()

# FastAPI UygulamasÄ±nÄ± BaÅŸlatma
app = FastAPI()
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")
llm = None  # Global LLM deÄŸiÅŸkeni
SESSIONS_FILE = "chat_history.json"

# API key kontrolÃ¼
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY bulunamadÄ±!")

print(f"API Key yÃ¼klendi: {api_key[:10]}...")

# Global deÄŸiÅŸkenler
vectorstore = None

# LLM Modelini BaÅŸlatma
def initialize_model():
    global llm
    try:
        llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-pro",
            google_api_key=api_key,
            temperature=0.3,
            convert_system_message_to_human=True,
            max_output_tokens=500
        )
        # Test mesajÄ±
        test_response = llm.invoke("Test mesajÄ±")
        print("âœ… Gemini 1.5 Pro baÅŸarÄ±yla yÃ¼klendi!")
        return True
    except Exception as e:
        print(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
        return False

# PDF yÃ¼kleme ve vektÃ¶r veritabanÄ± oluÅŸturma
def initialize_vectorstore():
    global vectorstore
    try:
        loader = PyPDFLoader("basketbol_kural.pdf")
        data = loader.load()
        
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)
        docs = text_splitter.split_documents(data)
        
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        vectorstore = Chroma.from_documents(
            documents=docs, 
            embedding=embeddings, 
            persist_directory="./chroma_db"
        )
        print("âœ… PDF baÅŸarÄ±yla yÃ¼klendi ve vektÃ¶r veritabanÄ± oluÅŸturuldu!")
    except Exception as e:
        print(f"âŒ PDF yÃ¼kleme hatasÄ±: {e}")

#AI Modelinden YanÄ±t Alma
def get_ai_response(question: str) -> str:
    try:
        if llm is None:
            return "Model henÃ¼z yÃ¼klenmedi. LÃ¼tfen daha sonra tekrar deneyin."
        
        if vectorstore is None:
            return "PDF veritabanÄ± henÃ¼z yÃ¼klenmedi. LÃ¼tfen daha sonra tekrar deneyin."

        # Benzer iÃ§erikleri getir
        retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 5})
        docs = retriever.get_relevant_documents(question)
        context = "\n".join([doc.page_content for doc in docs])

        system_prompt = ("Sen bir yardÄ±mcÄ± asistansÄ±n ve yalnÄ±zca basketbol kurallarÄ± hakkÄ±nda sorulara cevap veriyorsun. "
                        "YanÄ±tlarÄ±nÄ± yalnÄ±zca verilen baÄŸlam iÃ§eriÄŸinden oluÅŸtur. "
                        "EÄŸer sorunun cevabÄ±nÄ± bilmiyorsan, 'Bu konuda yardÄ±mcÄ± olamÄ±yorum.' de. "
                        "CevaplarÄ±nÄ± en fazla Ã¼Ã§ cÃ¼mle ile ver ve doÄŸru bilgi iÃ§erdiÄŸinden emin ol.\n\n"
                        f"BaÄŸlam:\n{context}")
        
        full_prompt = f"{system_prompt}\n\nSoru: {question}"
        
        response = llm.invoke(full_prompt)
        return response.content if hasattr(response, 'content') else str(response)
    except Exception as e:
        print(f"AI yanÄ±t hatasÄ±: {e}")
        return "ÃœzgÃ¼nÃ¼m, ÅŸu anda yanÄ±t veremiyorum. LÃ¼tfen daha sonra tekrar deneyin."

class QueryRequest(BaseModel):
    question: str

@app.on_event("startup")
async def startup_event():
    """Uygulama baÅŸlangÄ±cÄ±nda Ã§alÄ±ÅŸacak fonksiyon"""
    print("ğŸ“– Modeller yÃ¼kleniyor...")
    initialize_model()
    print("ğŸ“š PDF yÃ¼kleniyor...")
    initialize_vectorstore()

#API'nin Ana SayfasÄ±
@app.get("/")
def home(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

#Sohbet OturumlarÄ±nÄ± YÃ¶netme
@app.get("/sessions")
def list_sessions():
    """TÃ¼m sohbet oturumlarÄ±nÄ± listele"""
    data = load_chat_history()
    return data.get("sessions", [])

def load_chat_history() -> Dict:
    """Chat geÃ§miÅŸini yÃ¼kle"""
    if not os.path.exists(SESSIONS_FILE):
        return {"sessions": []}
    try:
        with open(SESSIONS_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"Chat geÃ§miÅŸi yÃ¼kleme hatasÄ±: {e}")
        return {"sessions": []}

def save_chat_history(data: Dict) -> None:
    """Chat geÃ§miÅŸini kaydet"""
    try:
        with open(SESSIONS_FILE, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Chat geÃ§miÅŸi kaydetme hatasÄ±: {e}")
        raise HTTPException(status_code=500, detail="Chat geÃ§miÅŸi kaydedilemedi")


# AÅAÄIDAN OTURUM YÃ–NETÄ°MÄ° Ä°Ã‡Ä°N EK KODLAR
def find_session(data: Dict, session_id: str) -> Optional[Dict]:
    """Belirli bir oturumu bul"""
    return next((s for s in data.get("sessions", []) if s["id"] == session_id), None)

def get_rag_response(question: str) -> str:
    """RAG zincirinden cevap alÄ±r ve metin cevabÄ± dÃ¶ndÃ¼rÃ¼r."""
    try:
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                response = rag_chain.invoke({"input": question}) # type: ignore
                return response["answer"]
            except Exception as e:
                if "429" in str(e) or "Resource has been exhausted" in str(e):
                    retry_count += 1
                    if retry_count >= max_retries:
                        raise APIQuotaExceeded("API kotasÄ± aÅŸÄ±ldÄ±. LÃ¼tfen daha sonra tekrar deneyin.") # type: ignore
                    time.sleep(2 ** retry_count)  # Exponential backoff
                else:
                    raise
    except Exception as e:
        print(f"RAG yanÄ±t hatasÄ±: {e}")
        if isinstance(e, APIQuotaExceeded): # type: ignore
            return "ÃœzgÃ¼nÃ¼m, ÅŸu anda Ã§ok yoÄŸunum. LÃ¼tfen biraz sonra tekrar deneyin."
        return "Bir hata oluÅŸtu. LÃ¼tfen tekrar deneyin."

@app.get("/sessions/{session_id}")
def get_session(session_id: str):
    """Belirli bir oturumun detaylarÄ±nÄ± getir"""
    data = load_chat_history()
    session = find_session(data, session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Oturum bulunamadÄ±")
    return session

#Yeni bir sohbet oturumu oluÅŸturma
@app.post("/sessions")
def create_session(request: QueryRequest):
    """Yeni bir sohbet oturumu oluÅŸtur"""
    try:
        data = load_chat_history()
        user_msg = request.question
        bot_msg = get_ai_response(user_msg)

        new_session = {
            "id": str(uuid.uuid4()),
            "title": user_msg[:30] + "..." if len(user_msg) > 30 else user_msg,
            "messages": [
                {"role": "user", "content": user_msg},
                {"role": "assistant", "content": bot_msg}
            ],
            "created_at": datetime.datetime.now().isoformat()
        }

        data["sessions"].append(new_session)
        save_chat_history(data)
        return new_session
    except Exception as e:
        print(f"Oturum oluÅŸturma hatasÄ±: {e}")
        raise HTTPException(status_code=500, detail=str(e))

#Oturuma yeni mesaj ekleme
@app.post("/sessions/{session_id}/messages")
def add_message(session_id: str, request: QueryRequest):
    """Mevcut oturuma yeni mesaj ekle"""
    try:
        data = load_chat_history()
        session = find_session(data, session_id)
        if not session:
            raise HTTPException(status_code=404, detail="Oturum bulunamadÄ±")

        user_msg = request.question
        bot_msg = get_ai_response(user_msg)

        session["messages"].append({"role": "user", "content": user_msg})
        session["messages"].append({"role": "assistant", "content": bot_msg})

        save_chat_history(data)
        return {"question": user_msg, "answer": bot_msg}
    except Exception as e:
        print(f"Mesaj ekleme hatasÄ±: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/sessions/{session_id}")
def delete_session(session_id: str):
    """Oturumu sil"""
    try:
        data = load_chat_history()
        data["sessions"] = [s for s in data["sessions"] if s["id"] != session_id]
        save_chat_history(data)
        return {"message": "Oturum silindi"}
    except Exception as e:
        print(f"Oturum silme hatasÄ±: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# BaÅŸlÄ±k gÃ¼ncelleme iÃ§in yeni model ekleyelim
class TitleUpdate(BaseModel):
    title: str

@app.put("/sessions/{session_id}/title")
def update_session_title(session_id: str, request: TitleUpdate):
    """Oturum baÅŸlÄ±ÄŸÄ±nÄ± gÃ¼nceller."""
    try:
        data = load_chat_history()
        
        # Oturumu bul
        session = None
        for s in data["sessions"]:
            if s["id"] == session_id:
                session = s
                break
                
        if not session:
            raise HTTPException(status_code=404, detail="Oturum bulunamadÄ±")
            
        # BaÅŸlÄ±ÄŸÄ± gÃ¼ncelle
        session["title"] = request.title
        save_chat_history(data)
        
        return {"status": "success", "message": "BaÅŸlÄ±k gÃ¼ncellendi"}
        
    except Exception as e:
        print(f"BaÅŸlÄ±k gÃ¼ncelleme hatasÄ±: {e}")
        raise HTTPException(status_code=500, detail=str(e))